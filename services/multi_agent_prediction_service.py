from typing import Dict, Any, List
from datetime import datetime
import asyncio
import json

from models.user_info import UserInfo
from models.prediction_result import PredictionResult
from services.bazi_service import BaziService
from services.agents import (
    FoundationAgent,
    YongshenAgent,
    FortuneAgent,
    LifeAspectsAgent,
    SolutionAgent,
    ConsultationAgent
)
from utils.logger import logger

class MultiAgentPredictionService:
    """å¤šæ™ºèƒ½ä½“é¢„æµ‹æœåŠ¡"""
    
    def __init__(self):
        self.bazi_service = BaziService()
        self._initialize_agents()
    
    def _initialize_agents(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ™ºèƒ½ä½“"""
        self.agents = {
            "foundation": FoundationAgent(),
            "yongshen": YongshenAgent(),
            "fortune": FortuneAgent(),
            "life_aspects": LifeAspectsAgent(),
            "solution": SolutionAgent(),
            "consultation": ConsultationAgent()
        }
        logger.info(f"åˆå§‹åŒ–äº† {len(self.agents)} ä¸ªä¸“ä¸šæ™ºèƒ½ä½“")
    
    async def get_comprehensive_prediction(self, user_info: UserInfo) -> PredictionResult:
        """èŽ·å–ç»¼åˆé¢„æµ‹ï¼ˆå¹¶è¡Œæ¨¡å¼ï¼‰"""
        logger.log_user_action("å¤šæ™ºèƒ½ä½“ç»¼åˆé¢„æµ‹è¯·æ±‚", user_info.dict())
        
        try:
            # èŽ·å–å…«å­—æ•°æ®
            logger.info("æ­£åœ¨èŽ·å–å…«å­—æ•°æ®...")
            fortune_data = self.bazi_service.get_fortune_analysis(user_info, 'comprehensive')
            
            # å‡†å¤‡å…±äº«ä¸Šä¸‹æ–‡
            shared_context = {
                "user_info": user_info,
                "fortune_data": fortune_data,
                "current_time": datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
            }
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ™ºèƒ½ä½“åˆ†æž
            logger.info("å¼€å§‹å¹¶è¡Œæ‰§è¡Œæ™ºèƒ½ä½“åˆ†æž...")
            start_time = datetime.now()
            
            analysis_results = await self._parallel_analysis(shared_context)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            logger.info(f"å¹¶è¡Œåˆ†æžå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            
            # èšåˆç»“æžœ
            prediction_content = self._merge_results(analysis_results)
            
            # åˆ›å»ºé¢„æµ‹ç»“æžœ
            result = PredictionResult(
                user_name=user_info.name,
                prediction_time=datetime.now(),
                prediction_content=prediction_content
            )
            
            logger.log_prediction_request(user_info.name, "å¤šæ™ºèƒ½ä½“ç»¼åˆé¢„æµ‹", True)
            total_length = prediction_content.get("summary", {}).get("total_content_length", 0)
            logger.info(f"é¢„æµ‹å®Œæˆï¼Œç”ŸæˆJSONç»“æž„åŒ–ç»“æžœï¼Œæ€»å†…å®¹é•¿åº¦: {total_length}å­—")
            
            return result
            
        except Exception as e:
            logger.error(f"å¤šæ™ºèƒ½ä½“é¢„æµ‹å¤±è´¥: {str(e)}")
            logger.log_prediction_request(user_info.name, "å¤šæ™ºèƒ½ä½“ç»¼åˆé¢„æµ‹", False, str(e))
            raise
    
    async def _parallel_analysis(self, shared_context: Dict[str, Any]) -> Dict[str, str]:
        """å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ™ºèƒ½ä½“åˆ†æž"""
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = {
            agent_name: agent.analyze(shared_context)
            for agent_name, agent in self.agents.items()
        }
        
        # è®°å½•å¹¶å‘å¼€å§‹æ—¶é—´
        start_time = datetime.now()
        logger.info(f"ðŸš€ å¼€å§‹å¹¶å‘æ‰§è¡Œ {len(tasks)} ä¸ªæ™ºèƒ½ä½“ä»»åŠ¡ï¼Œæ—¶é—´: {start_time.strftime('%H:%M:%S.%f')[:-3]}")
        for agent_name in tasks.keys():
            logger.info(f"ðŸ“‹ æ™ºèƒ½ä½“ {agent_name} ä»»åŠ¡å·²åˆ›å»º")
        
        # å¹¶è¡Œæ‰§è¡Œ
        try:
            results = await asyncio.gather(*tasks.values(), return_exceptions=True)
            
            # è®°å½•å¹¶å‘å®Œæˆæ—¶é—´
            end_time = datetime.now()
            total_duration = (end_time - start_time).total_seconds()
            logger.info(f"âš¡ æ‰€æœ‰æ™ºèƒ½ä½“ä»»åŠ¡å®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.2f}ç§’ï¼Œå®Œæˆæ—¶é—´: {end_time.strftime('%H:%M:%S.%f')[:-3]}")
            
            # å¤„ç†ç»“æžœ
            analysis_results = {}
            for i, (agent_name, result) in enumerate(zip(tasks.keys(), results)):
                current_time = datetime.now()
                if isinstance(result, Exception):
                    logger.error(f"âŒ {agent_name} æ™ºèƒ½ä½“åˆ†æžå¤±è´¥: {str(result)}")
                    analysis_results[agent_name] = f"{agent_name}åˆ†æžæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åŽé‡è¯•ã€‚"
                else:
                    analysis_results[agent_name] = result
                    logger.info(f"âœ… {agent_name} æ™ºèƒ½ä½“åˆ†æžæˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(result)}ï¼Œå¤„ç†æ—¶é—´: {current_time.strftime('%H:%M:%S.%f')[:-3]}")
            
            return analysis_results
            
        except Exception as e:
            logger.error(f"å¹¶è¡Œåˆ†æžæ‰§è¡Œå¤±è´¥: {str(e)}")
            raise
    
    def _merge_results(self, analysis_results: Dict[str, str]) -> Dict[str, Any]:
        """èšåˆæ‰€æœ‰æ™ºèƒ½ä½“çš„åˆ†æžç»“æžœä¸ºJSONå¯¹è±¡"""
        # æž„å»ºç»“æž„åŒ–çš„JSONç»“æžœ
        merged_result = {
            "report_info": {
                "title": "çŽ„å­¦AIæ™ºèƒ½ä½“ - ç»¼åˆå‘½ç†åˆ†æžæŠ¥å‘Š",
                "generated_time": datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S'),
                "service_provider": "çŽ„å­¦AIæ™ºèƒ½ä½“æœåŠ¡",
                "description": "æœ¬åˆ†æžæŠ¥å‘Šç”±å¤šä¸ªä¸“ä¸šæ™ºèƒ½ä½“ååŒç”Ÿæˆï¼Œä¸ºæ‚¨æä¾›å…¨æ–¹ä½çš„å‘½ç†æŒ‡å¯¼ã€‚"
            },
            "analysis_sections": {
                "foundation_analysis": {
                    "title": "å…«å­—åŸºç¡€åˆ†æž",
                    "content": analysis_results.get("foundation", "").strip(),
                    "agent": "foundation"
                },
                "yongshen_analysis": {
                    "title": "ç”¨ç¥žå–œå¿Œåˆ†æž",
                    "content": analysis_results.get("yongshen", "").strip(),
                    "agent": "yongshen"
                },
                "fortune_prediction": {
                    "title": "å¤§è¿æµå¹´é¢„æµ‹",
                    "content": analysis_results.get("fortune", "").strip(),
                    "agent": "fortune"
                },
                "life_aspects": {
                    "title": "äººç”Ÿå„æ–¹é¢è¯¦è§£",
                    "content": analysis_results.get("life_aspects", "").strip(),
                    "agent": "life_aspects"
                },
                "solutions": {
                    "title": "ä¸“ä¸šè§£å†³æ–¹æ¡ˆ",
                    "content": analysis_results.get("solution", "").strip(),
                    "agent": "solution"
                },
                "consultation": {
                    "title": "å’¨è¯¢é—®é¢˜å›žç­”",
                    "content": analysis_results.get("consultation", "").strip(),
                    "agent": "consultation"
                }
            },
            "summary": {
                "total_sections": len([k for k, v in analysis_results.items() if v and v.strip()]),
                "total_content_length": sum(len(v) for v in analysis_results.values() if v),
                "agents_used": list(analysis_results.keys())
            }
        }
        
        # ç§»é™¤ç©ºå†…å®¹çš„åˆ†æžéƒ¨åˆ†
        merged_result["analysis_sections"] = {
            k: v for k, v in merged_result["analysis_sections"].items() 
            if v["content"]
        }
        
        total_content_length = sum(
            len(section["content"]) 
            for section in merged_result["analysis_sections"].values()
        )
        
        logger.info(f"ç»“æžœèšåˆå®Œæˆï¼Œç”ŸæˆJSONå¯¹è±¡åŒ…å« {len(merged_result['analysis_sections'])} ä¸ªåˆ†æžéƒ¨åˆ†ï¼Œæ€»å†…å®¹é•¿åº¦: {total_content_length}å­—")
        
        return merged_result
    
    def get_agent_status(self) -> Dict[str, Any]:
        """èŽ·å–æ‰€æœ‰æ™ºèƒ½ä½“çŠ¶æ€"""
        status = {
            "total_agents": len(self.agents),
            "agents": {
                agent_name: {
                    "name": agent.agent_name,
                    "status": "ready"
                }
                for agent_name, agent in self.agents.items()
            },
            "service_status": "ready"
        }
        return status
    
    async def test_agents(self, user_info: UserInfo) -> Dict[str, Any]:
        """æµ‹è¯•æ‰€æœ‰æ™ºèƒ½ä½“ï¼ˆç”¨äºŽè°ƒè¯•ï¼‰"""
        try:
            # èŽ·å–æµ‹è¯•æ•°æ®
            fortune_data = self.bazi_service.get_fortune_analysis(user_info, 'comprehensive')
            
            shared_context = {
                "user_info": user_info,
                "fortune_data": fortune_data,
                "current_time": datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
            }
            
            # æµ‹è¯•æ¯ä¸ªæ™ºèƒ½ä½“
            test_results = {}
            for agent_name, agent in self.agents.items():
                try:
                    start_time = datetime.now()
                    result = await agent.analyze(shared_context)
                    end_time = datetime.now()
                    duration = (end_time - start_time).total_seconds()
                    
                    test_results[agent_name] = {
                        "status": "success",
                        "duration": duration,
                        "content_length": len(result),
                        "content_preview": result[:100] + "..." if len(result) > 100 else result
                    }
                except Exception as e:
                    test_results[agent_name] = {
                        "status": "failed",
                        "error": str(e)
                    }
            
            return test_results
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä½“æµ‹è¯•å¤±è´¥: {str(e)}")
            return {"error": str(e)}